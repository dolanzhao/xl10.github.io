很高兴在CCCF这个平台和大家分享一下自己的近期在超级计算和并行计算领域做研究的一些体会。超级计算一直是各大国之间角逐的领域.超级计算又可以细分为支撑超级计算的硬件，上层的应用软件，以及连接硬件和应用软件的系统软件。国内在硬件和软件两个领域都取得了世界瞩目的成就。在硬件领域，国际专家委员会维护一个称为top500名单，给全世界最快的500台超级计算机的速度来排名。这份名单在每年的6月和11月都会更新。国内制造的超级计算机例如天河二号和神威-太湖之光已经连续多年蝉联榜首。值得一提的是，神威-太湖之光已经使用了国产的芯片，走在了世界的前列。在软件领域，国内科学家开发出了一套大气动力学的软件获得了2016年超级计算软件的最高奖---戈登贝尔奖（Gordon Bell Prize）。与此同时，美国也在进行着CORAL项目和中国竞争。这个项目是美国能源部下多个国家实验室和工业界紧密合作，将在2017年研发和部署最新的超级计算机。

超级计算机的硬件和应用软件分别是整个超级计算机系统的最底层和最上层，在它们之间还存在着我们称之为软件栈（software stack）的系统软件，包括编译器，并行运行环境，作业调度系统，性能分析工具等等。系统软件能紧密结合硬件和应用软件进而得到最高的硬件使用效率和最快的软件运行速度。长期以来有效的系统软件是科研工作者研究的热点。我的研究领域也是超级计算机的系统软件，具体一些就是程序性能分析工具。在本文中，我将介绍自己对本领域的一些认识和理解，然后分享一些自己自己的研究体会。文章中都是我个人的观点，希望能够抛砖引玉和各位专家探讨。

对研究领域的理解
我首先展开介绍一下性能分析工具的研究，然后讨论一下相关的会议中对性能分析工具的评审，最后展望一些对性能分析工具的研究发展。

1. 研究领域 — 什么是程序性能分析工具
程序性能分析工具（profiler）是通过静态（static）或者动态（dynamic）程序分析来指出程序运行时的性能瓶颈，并给出反馈给用户（程序开发者或者编译器）来进行优化。通常编写一个高效的应用软件是非常困难的，特别是对于动辄几百万行代码的复杂的超级计算并行应用程序。很多并行程序会遇到各种性能问题，例如软件问题（低效的算法，不合适的数据结构），编译器问题（编译器低效的生成代码），运行时问题（并行的开销，负载不均衡，线程进程同步和通信的开销，内存缓存和带宽的低效使用）等等。通常情况下，寻找这些性能瓶颈需要大量的人力，所以研究人员一般依赖性能分析工具来对程序进行自动化的分析。

现有的部署在超级计算机上的主流性能分析工具（Intel的商业工具VTune，University of Oregon的TAU，Rice University的HPCToolkit，欧洲的Scalasca等等）主要依赖动态程序分析，同时也会用一些静态信息作为辅助。动态分析的工作流程是首先运行一遍待分析的程序，同时分析工具动态的监测程序的运行并收集相关的性能指标。等程序运行结束，性能工具把所有的性能数据写入文件或者数据库（称之为profile）以待后续分析。一般情况下，性能分析工具会有一个线下的分析模块来处理所有的性能数据并将之关联到程序的源代码中。用户进而根据分析结果来优化程序。如果仍然得不到预期的性能，用户可以重复之前的流程来逐步优化各个性能瓶颈。

2. 论文的评审 — 什么是好的性能分析工具
长期以来，关于程序性能分析工具的论文主要发表在SC, CGO, PPoPP, PLDI，IPDPS等会议上并且多次获得最佳论文。近些年来，一些顶级的系统会议也乐于接收性能分析工具的文章。例如SOSP15收录了University of Massachusett的COZ性能分析工具。COZ可以用来分析并行程序的关键路径（critical path），进而指出和性能紧密相关的关键代码来优化。COZ被SOSP15评为了最佳论文。另外ASPLOS17收录了我们的RedSpy性能分析工具。RedSpy是一个细粒度的分析工具来分析程序冗余的内存写入（memory write）指令。RedSpy被提名为ASPLOS17的最佳论文。

根据我投稿和审稿的经验，评价性能分析工具比较直接明了。一篇高档次的论文一般都具有以下几个特点：第一研究贡献：这些论文都能发现现有的工具不能发现的性能问题，或者付出较小的代价来发现已有的性能问题。这一般需要性能工具采用一些创新的检测或者分析方法。第二系统实现：这些论文都详细阐述了性能工具实现中遇到的各种问题和挑战，比如如何降低性能分析的开销，如果处理多线程和多进程的程序，如何更直观的给用户提供分析结果。第三系统评测：对工具详细的性能评测包括工具运行时的时间和内存开销，以及是否能发现已有的相关工具所不能发现的性能问题。同时系统评测还包括有说服力的案例分析（case study）来展示工具的创新性和可用性。这里我想展开谈一谈案例分析。

什么样的案例分析是有说服力的呢？一方面是大家通用的程序集，例如SPEC，PARSEC，NPB，以及一些美国能源部国家实验室发布的程序集Sequoia，CORAL，APEX。这些程序集大多已经发布了十年以上并经过多次反复优化。同时当前很多研究人员也致力于优化这些程序并且发表优化的结果。可以说这些程序集已经成为评估硬件，编译器，以及性能工具的标准程序集。如果一个性能分析工具仍然能在这些程序集里找到之前没有发现的优化机会，这个性能工具是有创新的。另一方面，如果一个性能分析工具能找到现有的重要的应用程序上的性能问题，把它们作为案例分析也是非常有说服力的。比如我们之前在美国能源部下太平洋西北国家实验室开发的计算化学软件NWChem里发现了性能问题并给出了优化方案，使得有六百万行代码的NWChem性能得到了1.5倍的提升。用真实的重要的应用程序作为案例分析既能证明工具的鲁棒性又能引起审稿人的兴趣。

3. 未来展望 — 性能分析工具的发展
性能分析工具在超级计算机的软件栈（software stack）占据了重要的位置。近些年，为推动性能分析工具的发展，业界每年都会在加利福尼亚州的Lake Tahoe举行为期四天的研讨会（workshop）来讨论未来性能工具的发展趋势。与会的专家来自工业界（google，cray，Intel，IBM），学术界(University of Wisconsin, Rice University, UT Austin，University of Oregon), 国家实验室和超算中心（Lawrence Livermore National Laboratory，Julich Supercomputer Center，Barcelona Supercomputer Center）。近些年来，北京航空航天大学钱德沛教授团队也来参加这个研讨会和国外同行来研讨。

根据我自己的研究经历和从近十次工具研讨会得到的一些经验，我个人认为性能分析领域未来会朝着一下几个方向发展。
（1）【可扩展到百亿亿次（exascale）超级计算机的性能分析工具】设计可扩展在百亿亿次超级计算机上运行的应用程序非常有挑战性。这就需要性能分析工具指出并消除影响可扩展性的性能瓶颈。但是性能工具运行在大规模并行计算机上面临着如何在收集到的大量数据中找到性能问题并展示给用户的挑战。同时性能分析的开销要足够小进而不能成为运行时的可扩展性瓶颈，否则工具收集到的数据很难暴露出低效的软件和硬件交互，并且用户也不会很容易接受使用这个工具。
（2）【语意级别（semantic level）的性能分析】现有的性能分析工具大多数找到程序的热点并且关联到程序的循环体或者函数。热点分析固然不可或缺，但是提供的信息相对较少。比如性能工具指出一个函数耗费了大量的运行时间并造成了大量的缓存缺失，但是分析出真正的原因并给出针对性的优化策略还需要进而的人工分析。所以性能分析工具将来向语意分析的方向发展来提供高层次的算法，数据结构信息作为热点分析的补充。这样的性能工具会给更准确的判断出性能瓶颈并且全自动的给出性能瓶颈的原因作为程序优化的参考。

一些研究体会
我中科院计算所读了三年硕士，在莱斯大学（Rice University）读了五年的博士，现在在威廉玛丽学院（College of William & Mary）入职三年助理教授。这十多年我一直从事性能分析工具的研究并有以下三点深刻的体会：

1. 重视研究的积累
现有的主流性能分析工具都有长时间的开发积累。例如Intel的VTune，University of Oregon的TAU，以及Rice University的HPCToolkit都有十年以上的开发经历。这样长时间的开发经历让这些性能分析工具愈加完善，同时一些新的想法基于已有的开发框架也更容易实现和更有说服力。我现在的研究主要集中在两个性能分析工具上，一个是HPCToolkit，另一个是CCTLib。基于这两个工具我们都发表了一系列论文并且在近期获得主要会议上的最佳论文或者最佳论文提名。

HPCToolkit是我延续在莱斯大学的研究路线。我在HPCToolkit中加入了以数据结构为中心的性能分析，进而能更轻量级的分析和内存相关的性能瓶颈。在这项工作之前，传统的性能工具需要通过插桩（instrumentation）和模拟（simulation）来得到内存相关的性能瓶颈。这些传统工具一般要产生十几倍到几百倍的运行时间开销（overhead），非常不利于应用在检测大型超级计算程序上。我的工作是通过使用硬件计数器（performance counter）把这个时间开销降低到了10%一下。我们在SC’13，PPoPP’14，PACT’14发表了一系列的论文在讲述这个轻量级的性能分析工具对不同内存性能问题的分析，并在SC’15获得了唯一的最佳论文。

CCTLib是我们为性能分析工具开发者所研发的一套细粒度性能分析工具框架。基于CCTLib，我们开发了一系列的细粒度的工具来寻找程序中的冗余计算以及冗余的内存操作。对于这些冗余的操作，传统的性能分析工具很难找到它们。我们发表了一系列的论文在CGO’14，PACT’15，ISMM’16探讨CCTLib的应用。我们最新的论文发表在ASPLOS’17并被提名为最佳论文。

在我来看，如果没有长时间积累，我们的工作很难在这些主要会议上得到认可。

2. 开发有实际用途的工具
若要让用户认可一个性能分析工具并真正应用在自己的研究或者开发环境中，这个性能分析工具必须要有自己独有的特点。现有的主流工具都具备这个特点。比如VTune能更好的利用Intel处理器上的性能检测单元（PMU)，TAU支持不同级别的程序插桩可以快速的移植到各个不同的系统平台，HPCToolkit支持准确的轻量级的调用堆栈展开（call stack unwinding）以及性能瓶颈原因分析（root cause analysis）,CCTLib 可以支持细粒度的程序分析进而可以指出冗余的和不必要的操作。正因为这些不同的特性，这些工具根据不同的需要有不同的应用场景。

作为能够实用的工具，除了具备新颖的分析方法，直观的分析结果展示方法也非常重要。这是因为大多数用户是应用程序开发者而不是计算机系统的专家，让这些用户感觉到工具“好用”是非常关键的。通常用户习惯使用一个工具后他们很少再去更换去使用别的工具。同时如果一个工具给用户的第一印象不好，那么以后也很难说服用户改变他们的看法。基于这个原因，很多工具研发人员都会设计直观的图形界面（graphic user interface）来直观的显示出程序的性能问题。所以研发一个实用的性能工具需要一定的工程量。

3. 对研究结果的宣传
众所周知，发表高档次的论文并在会议上演讲是推销自己研究成果行之有效的方法。除此之外，还有三个方法能有效的扩大自己研究的影响力以得到更广泛的关注：系统的开源，和用户的沟通，以及在会议上组织工具的教程（tutorial）。我通过我的导师John Mellor-Crummey教授的经历来介绍这几种推销方法。

John Mellor-Crummey教授是HPCToolkit开源工具的维护者。我们要提交代码都需要通过他的代码审核（code review）来保证HPCToolkit的代码质量。同时他也是一个非常优秀的程序员，长期工作在代码编程的第一线。开源的HPCToolkit也得到了更多用户的使用和认可。

John Mellor-Crummey教授每年都会去美国能源部下属的各个国家实验室去和超级计算应用开发者去研讨。他会详细的询问应用开发人员对性能工具的需求以及他们感兴趣的系统结构和应用。之后他会有针对性的开发HPCToolkit并推销给这些用户去使用。所以HPCToolkit已经部署在绝大多数国家实验室的超级计算机上。

John Mellor-Crummey教授会在一些主流会议上组织HPCToolkit的教程来从与会者中吸引更多的用户。类似于我的导师，我也在2017年的CGO组织了CCTLib的教程。组织一个教程不是容易的事情，我们前前后后花费了近一个月的时间准备演讲稿（slides），性能工具安装使用教程，以及直观的教程用例。我们吸引了美国和欧洲的一些工业界和学术界的开发人员来参加教程并且让他们使用和参与开发CCTLib。

总结
随着超级计算硬件和应用软件的迅猛发展，未来对对性能工具这样的系统软件工具会有更多更高的要求。我希望能有更多的研究人员能加入这个领域，致力于提高计算机的软件的效率和硬件的使用率。 


